{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LLM Model\n",
    "\n",
    "## Transformer Model from Hugging Face\n",
    "\n",
    "https://huggingface.co/Waterhorse/chessgpt-base-v1"
   ],
   "id": "a91df9616dafff10"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:16:49.615219Z",
     "start_time": "2024-12-06T05:16:49.597488Z"
    }
   },
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T05:17:11.042305Z",
     "start_time": "2024-12-06T05:17:11.037764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MIN_TRANSFORMERS_VERSION = '4.25.1'\n",
    "assert transformers.__version__ >= MIN_TRANSFORMERS_VERSION, f'Please upgrade transformers to version {MIN_TRANSFORMERS_VERSION} or higher.'\n"
   ],
   "id": "3ef096b1e7be3420",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:07:25.134298Z",
     "start_time": "2024-12-06T16:06:37.030160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# init\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Waterhorse/chessgpt-base-v1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Waterhorse/chessgpt-base-v1\", torch_dtype=torch.float16)\n"
   ],
   "id": "7749bdf5a0bac662",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.96s/it]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:28:00.888647Z",
     "start_time": "2024-12-06T16:07:43.751320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# infer\n",
    "# Conversation between two\n",
    "prompt = \"You are a chess engine. I give you a Fen position and you give an evaluation of the position. That should be an integer, positive if white are in advantage, negative if black are in advantage. Here is the Fen position: rnbqkbnr/pp1ppppp/8/2p5/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2 A:\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "input_length = inputs.input_ids.shape[1]\n",
    "outputs = model.generate(\n",
    "    **inputs, max_new_tokens=128, do_sample=True, temperature=0.7, top_p=0.7, top_k=50, return_dict_in_generate=True,\n",
    ")\n",
    "token = outputs.sequences[0, input_length:]\n",
    "output_str = tokenizer.decode(token)\n",
    "print(output_str)"
   ],
   "id": "3d2e5978fd1542d5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "You should output a value of -1 if white are in advantage, 0 if black are in advantage.\n",
      "\n",
      "I don't know how to write a chess engine in C++. I am using the chess programming wiki.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use a bitboard representation for chess. You can use a bitboard representation for chess in C++ as well. The bitboard representation for chess is:\n",
      "unsigned long long board[8][8] = {\n",
      "    { 0, 0, 0, 0, 0, 0, 0, 0 },\n",
      "    { 0, 0, 0, 0\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Google GenerativeAI\n",
    "\n",
    "Documentation: https://ai.google.dev/gemini-api/docs/quickstart?hl=en&lang=python"
   ],
   "id": "f808cff629482f29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:03:09.878926Z",
     "start_time": "2024-12-06T16:03:09.859888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import google.generativeai as genai\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
   ],
   "id": "7168bea838010e5e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:03:52.956898Z",
     "start_time": "2024-12-06T16:03:47.212887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10) :\n",
    "    response = model.generate_content(\"You are a chess engine. I give you a Fen position and you give an evaluation of the position. That should be an integer, positive if white are in advantage, negative if black are in advantage. Here is the Fen position: rnbqkbnr/pp1ppppp/8/2p5/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2\")\n",
    "\n",
    "    print(response.text)"
   ],
   "id": "26d8c992cdd42aee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "-20\n",
      "\n",
      "-30\n",
      "\n",
      "-3\n",
      "\n",
      "-20\n",
      "\n",
      "-20\n",
      "\n",
      "0\n",
      "\n",
      "-20\n",
      "\n",
      "-20\n",
      "\n",
      "-20\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6be84d091d48252b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
